using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using Emgu.CV;
using Emgu.CV.CvEnum;
using Emgu.CV.Structure;
using Emgu.CV.UI;
using System.Diagnostics;
using Emgu.CV.Cuda;
using Emgu.CV.VideoSurveillance;
using System.IO;
using System.Configuration;


namespace Ungu_CV1
{
    /**
     * Lurker Van Gogh
     *
     * 
     * **/

    public partial class Form1 : Form
    {
        
        Capture capWebcam = null;
        bool blnCaptureingInProcess = false;
        Image<Bgr, Byte> imgOriginal;
        Image<Bgr, Byte> imgVanGoh;
        Image<Bgr, Byte> imgProcessed;
        List<Image<Gray, Byte>> faces;
        CascadeClassifier active_cascade = null;
        CascadeClassifier face_cascade;
        CascadeClassifier face2_cascade;
        CascadeClassifier facea_cascade;
        CascadeClassifier facep_cascade; 
        CascadeClassifier bodyu_cascade;
        CascadeClassifier bodyf_cascade;
        CascadeClassifier bodyl_cascade; //haarcascade_lowerbody.xml
        OpenFileDialog OF = new OpenFileDialog();
        SaveFileDialog SF = new SaveFileDialog();
        //current video mode and state
        bool playstate = false;
        bool recordstate = false;

        VideoMethod CurrentState = VideoMethod.Viewing; //default state
        public enum VideoMethod
        {
            Viewing,
            Recording
        };

        double scaleFactor = 1.07;
        int minNeighbors = 2; //Minimum number (minus 1) of neighbor rectangles that makes up an object. All the groups of a smaller number of rectangles than min_neighbors-1 are rejected. If min_neighbors is 0, the function does not any grouping at all and returns all the detected candidate rectangles, which may be useful if the user wants to apply a customized grouping procedure
        Size minSize = new Size(10, 10); //By default, it is set to the size of samples the classifier has been trained on ( \sim 20\times 20 for face detection)
        Size maxSize = new Size(200, 200);
        Image<Bgr, Byte> fgMaskMOG; //fg mask generated by MOG method
        Image<Bgr, Byte> fgMaskMOG2; //fg mask fg mask generated by MOG2 method
        //BackgroundSubstractor pMOG; //MOG Background subtractor
        //BackgroundSubstractor pMOG2; //MOG2 Background subtractor
        Image<Bgr, byte> Background;
        int frameCount = 0;
        int trainingCount = 0;
        Stopwatch watch = new Stopwatch();
        Rectangle[] lastRectangle = null;
        Bgr drawBoxColor = new Bgr(0, double.MaxValue, 50);

        FaceCounter fc = new FaceCounter();
        int NumberOfFaces =0;
        double NumberOfFacesSmooth = 0;

        Size window1 = new Size(30, 30);
        Size window2 = new Size(30, 30);
        Size window3 = new Size(30, 30);
        Size window4 = new Size(30, 30);
        Size window5 = new Size(30, 30);
        Size window6 = new Size(30, 30);

        double resizeImage = 1;
        double maxWidth = 360;
        //Parameters:	
        //cascade – Haar classifier cascade (OpenCV 1.x API only). It can be loaded from XML or YAML file using Load(). When the cascade is not needed anymore, release it using cvReleaseHaarClassifierCascade(&cascade).
        //image – Matrix of the type CV_8U containing an image where objects are detected.
        //objects – Vector of rectangles where each rectangle contains the detected object.
        //scaleFactor – Parameter specifying how much the image size is reduced at each image scale.
        //minNeighbors – Parameter specifying how many neighbors each candidate rectangle should have to retain it.
        //flags – Parameter with the same meaning for an old cascade as in the function cvHaarDetectObjects. It is not used for a new cascade.
        //minSize – Minimum possible object size. Objects smaller than that are ignored.
        //maxSize – Maximum possible object size. Objects larger than that are ignored.

        public Form1()
        {
            InitializeComponent();
        }

        private void Form1_Load(object sender, EventArgs e)
        {
            // get the list of images from images & videos directory
            populateListofImages();
            populateListofVideos();         

            try
            {
                watch.Start();
                Debug.WriteLine("has Cude Cuda really? = " + CudaInvoke.HasCuda);
                // adjust path to find your xml
                //face_cascade = new CascadeClassifier("haar\\haarcascade_frontalface_alt2.xml");
                //haarcascade_frontalface_default.xml
                face_cascade = new CascadeClassifier("haar\\haarcascade_frontalface_default.xml");
                face2_cascade = new CascadeClassifier("haar\\haarcascade_frontalface_alt2.xml");
                facea_cascade = new CascadeClassifier("haar\\haarcascade_frontalface_alt.xml");
                facep_cascade = new CascadeClassifier("haar\\haarcascade_profileface.xml");
                bodyl_cascade = new CascadeClassifier("haar\\haarcascade_lowerbody.xml");
                bodyu_cascade = new CascadeClassifier("haar\\haarcascade_upperbody.xml");
                bodyf_cascade = new CascadeClassifier("haar\\haarcascade_fullbody.xml");
                active_cascade = face_cascade;

                capWebcam = new Capture(); // assocate capture object to default web cam
                capturePicture();

                //imgOriginal = capWebcam.QueryFrame(); // gets next frame
                capturePicture();
                

            }
            catch (Exception exp) {
                Debug.WriteLine("error null? =" + exp);
                textBox1.Text = exp.Message;
                imgOriginal = getDefaultOriginal();
                //if (capWebcam==null)
                //    return;
            }
            // start with video capture on by default
            //Application.Idle += processFrameAndUpdateGUI; // adds image function. 
            //blnCaptureingInProcess = true;
            //textBox1.AppendText("application capturing video" + blnCaptureingInProcess);
            //imageBoxProcesssed.Image = pMOG.ForgroundMask;

            // start button off in false mode. 
            Application.Idle -= processFrameAndUpdateGUI; // turns off trigger alert
            blnCaptureingInProcess = false;
            textBox1.AppendText("Not capturing video" + blnCaptureingInProcess);
            
                listBoxPictureList.SelectedIndex = 0;
                imgVanGoh = getSelectedVanGo();
                this.imageBoxOrig.Image = imgOriginal.Resize(imageBoxOrig.Width, imageBoxOrig.Height, Inter.Cubic, true);
                this.imageBoxProcesssed.Image = imgVanGoh.Copy().Resize(imageBoxOrig.Width, imageBoxOrig.Height, Inter.Cubic, true); 
                configureWindows();
            // face counter 

            fc.cap = this.capWebcam;
            fc.ConfigureCascade();
            fc.scaleFactor = this.scaleFactor;
            fc.minNeighbors = this.minNeighbors;
            fc.maxSize = this.maxSize;
            fc.minSize = this.minSize;
            fc.convertColorImageSetGrey(imgOriginal);
            textBox1.AppendText(" \n init facecount = " + fc.NumberOfFacesCounted);

            listBoxMinNeighbors.SelectedItem=minNeighbors;
            Debug.WriteLine("maxSize.Height=" + maxSize.Height + " listBoxMax index=" + listBoxMax.Items.IndexOf(maxSize.Height.ToString()));
            listBoxMax.SetSelected(listBoxMax.Items.IndexOf(maxSize.Height.ToString()), true);
            listBoxMinSize.SetSelected(listBoxMinSize.Items.IndexOf(minSize.Height.ToString()), true);
            listBoxMinNeighbors.SetSelected(listBoxMinNeighbors.Items.IndexOf(minNeighbors.ToString()), true);
            listBoxScaleFactor.SetSelected(listBoxScaleFactor.Items.IndexOf(scaleFactor.ToString()), true);
            listBoxClassifier.SetSelected(0, true);


            //imageWindow1.Parent = imageBoxProcesssed;
            //imageWindow1.BringToFront();
            imageWindow1.BackColor = Color.Transparent;
        }

        void configureWindows()
        {
            Debug.WriteLine("configureWindows here.");
            // scale size location of window. 
            // x=361 and y = 324
            Image<Bgr, Byte> imgcutter = imgVanGoh.Copy();
            double scaleIt = 361.0 / (double)imageBoxProcesssed.Size.Width;
            //imageWindow1.Location = new Point(imageBoxProcesssed.Location.X + (int)(90 * scaleIt), imageBoxProcesssed.Location.Y + (int)(5 * scaleIt) );
            //imageWindow1.Size = new Size((int)(45 * scaleIt), (int)(45 * scaleIt));
            imageWindow1.Image = imgcutter.Copy(new Rectangle(new Point(90, 5), new Size(45, 45)));

            //imageWindow2.Location = new Point(imageBoxProcesssed.Location.X + (int)(90 * scaleIt), imageBoxProcesssed.Location.Y + (int)(51* scaleIt));
            //imageWindow2.Size = new Size((int)(45 * scaleIt), (int)(45 * scaleIt));
            imageWindow2.Image = imgcutter.Copy(new Rectangle(new Point(90, 51), new Size(45, 45)));

            //imageWindow3.Location = new Point(imageBoxProcesssed.Location.X + (int)(90*scaleIt), imageBoxProcesssed.Location.Y + (int)(99*scaleIt));
            //imageWindow3.Size = new Size((int)(45 * scaleIt), (int)(45 * scaleIt));
            imageWindow3.Image = imgcutter.Copy(new Rectangle(new Point(90, 99), new Size(45, 45)));

        }
        Image<Bgr, Byte> getSelectedVanGo()
        {
            int vg = listBoxPictureList.FindString("images\\VanGo-roomwindow.png");
            if (vg < 0)
                vg = 0;
            String imageFileName = listBoxPictureList.Items[vg].ToString();
            Debug.WriteLine("vg image id is =" + vg + " filename is:" + imageFileName);
            Image<Bgr, Byte> img1 = new Image<Bgr, Byte>(imageFileName);
            return img1;
        }

        Image<Bgr, Byte> getImageUsingFileName(String imageFileName)
        {
            //new Bgr(255.0, 255.0, 255.0), 2),

            Image<Bgr, Byte> img1=   new Image<Bgr, Byte>(40,40) ;  //need to put a default oops. 
            try
            {
                Debug.WriteLine("getImageUsingFileName is =" +  imageFileName);
                img1 = new Image<Bgr, Byte>(imageFileName);
            }
            catch (Exception imgexp)
            {
                Debug.WriteLine("FAILED - getImageUsingFileName" + imgexp);
            }
            return img1;
        }

        /// <summary>
        /// getDefaultOriginal
        /// </summary>
        /// <returns></returns>
        /// 
        Image<Bgr, Byte> getDefaultOriginal()
        {
            int vg = listBoxPictureList.FindString("images\\testwalkby.jpg");
            if (vg < 0)
                vg = 0;
            String imageFileName = listBoxPictureList.Items[vg].ToString();
            return getImageUsingFileName(imageFileName);
        }

        Image<Bgr, Byte> getSelectedImage()
        {
            String imageFileName = listBoxPictureList.SelectedItem.ToString();
            Debug.WriteLine("getSelectedImage=" + imageFileName);
            Image<Bgr, Byte> img1 = new Image<Bgr, Byte>(imageFileName);
            return img1;
        }

        void capturePicture()
        {
            //Debug.WriteLine("processFrameAndUpdateGUI");
            imgOriginal = capWebcam.QueryFrame().ToImage<Bgr, Byte>(); // gets next frame
            if (imgOriginal == null) return;
            // (double)imageBoxOrig.Size.Width
            resizeImage = maxWidth / (double)imgOriginal.Size.Width;
            imgOriginal = imgOriginal.Resize(resizeImage, Inter.Cubic);
            imageBoxOrig.Image =  processImage(imgOriginal);
        }

        Image<Bgr, byte> processImage(Image<Bgr, byte> imgOrig)
        {
            Image<Bgr, byte> procImage = null;
            //Image<Gray, Byte> grayScale = null;
            //imgProcessed = imgOrig.InRange(new Bgr(0, 0, 175), new Bgr(100, 100, 256));
            //grayScale = imgOrig.Convert<Gray, Byte>();
            //grayScale = grayScale.SmoothGaussian(49);  // x and y size of the filter calll

            if (face_cascade != null)
            {
                procImage = processColorFace(imgOrig);
                //imageBoxProcesssed.Image = procImage;

                // remove background logic. 
                //imgProcessed = bsFilter2();
                //imageBoxProcesssed.Image = imgProcessed;
                //imageBoxProcesssed.Image = processFace(imgProcessed);//processFace(imgProcessed); bsFilter(imgProcessed); 
            }
            else
            {
                textBox1.AppendText("\n face_cascade NOT working!  ");
            }

            return procImage;
        }

        void processFrameAndUpdateGUI(object sender, EventArgs e)
        {
            frameCount++;
            if (frameCount > 30)
            {
                watch.Stop();
                var timeSpan = watch.ElapsedMilliseconds;
                frameCount = 0;
                textBox1.AppendText("\n frame count 30= " + timeSpan + " ms");
                Debug.WriteLine("frame count 30= " + timeSpan + " ms");
                watch.Restart();
            }
            //Debug.WriteLine("processFrameAndUpdateGUI");
            //imgOriginal = capWebcam.QueryFrame(); // gets next frame
            //if (imgOriginal == null) return;

            capturePicture();

            imageBoxOrig.Image = imgOriginal;
            //Image<Gray, Byte> imgGrayScale = null;
            //imgProcessed = processImage(Image<Bgr, byte> imgOrig);
            //imgProcessed = imgOriginal.InRange(new Bgr(0, 0, 175), new Bgr(100, 100, 256));
            //imgGrayScale = imgOriginal.Convert<Gray, Byte>();
            //imgGrayScale = imgGrayScale.SmoothGaussian(49);  // x and y size of the filter calll

            //if (face_cascade != null) {
            //    imageBoxOrig.Image = processColorFace(imgOriginal.Copy());
            //    // un rem this if you want back ground filtering to work
            //    //imgProcessed = bsFilter2();
            //    //imageBoxProcesssed.Image = imgProcessed;
            //    //imageBoxProcesssed.Image = processFace(imgProcessed);//processFace(imgProcessed); bsFilter(imgProcessed); 
            //}
            //else
            //{
            //    imageBoxOrig.Image = imgOriginal;
            //    //imageBoxProcesssed.Image = imgProcessed;
            //}

            textBox1.AppendText("\n NumberOfFacesSmooth=" + NumberOfFacesSmooth + " \n NumberOfFaces=" + NumberOfFaces + "\n " + Math.Round(NumberOfFacesSmooth));
        }

        Image<Bgr, byte> processColorFace(Image<Bgr, byte> nextFrame)
        {
            Image<Gray, byte> grayframe = nextFrame.Convert<Gray, byte>();
            //grayframe = grayframe.SmoothGaussian(49);  // x and y size of the filter calll

            // abstract out for other classifiers face_cascade.DetectMultiScale(grayframe, scaleFactor, minNeighbors, minSize, maxSize)
            Rectangle[] rectangles = processDetectMultiScale(active_cascade, grayframe);
            lastRectangle = rectangles;
            Debug.WriteLine("processColorFace - rectangles.Count=" + rectangles.Count());
            NumberOfFaces = 0;
            foreach (var face in rectangles)
            {
                NumberOfFaces++;
                if (imgOriginal!=null)
                    imgOriginal.Draw(face, drawBoxColor , 3);
            }

            if (imageWindow1 != null && imgOriginal != null)
            {
                double resizeScale = 1; 
                Image<Bgr, byte> imgCut = null;
                if (rectangles.Count<Rectangle>() >= 1)
                {
                    imgCut = nextFrame.Copy(rectangles[0]);
                    //resizeScale = ((double)imageWindow1.Size.Width / (double)imgCut.Width);
                    Debug.WriteLine("Resize of faceis " + resizeScale + "cause imgCut.Width=" + imgCut.Width + " imageWindow1.Size.Width=" + imageWindow1.Size.Width);
                    imageWindow1.Image = imgCut;//.Resize(resizeScale, INTER.CV_INTER_AREA);
                    imageWindow1.Visible = true;
                    if (rectangles.Count<Rectangle>() >= 2)
                    {
                        imgCut = nextFrame.Copy(rectangles[1]);
                        //resizeScale = imageWindow2.Image.Size.Width / imgCut.Width;
                        imageWindow2.Image = imgCut;//.Resize(resizeScale, INTER.CV_INTER_AREA);
                        imageWindow2.Visible = true;
                        if (rectangles.Count<Rectangle>() >= 3)
                        {
                            imgCut = nextFrame.Copy(rectangles[2]);
                            //resizeScale = imageWindow3.Image.Size.Width / imgCut.Width;
                            imageWindow3.Image = imgCut;//.Resize(resizeScale, INTER.CV_INTER_AREA);
                            imageWindow3.Visible = true;
                            if (rectangles.Count<Rectangle>() >= 4)
                            {
                                imgCut = nextFrame.Copy(rectangles[3]);
                                //resizeScale = imageWindow4.Image.Size.Width / imgCut.Width;
                                imageWindow4.Image = imgCut;//.Resize(resizeScale, INTER.CV_INTER_AREA);
                                imageWindow4.Visible = true;
                                if (rectangles.Count<Rectangle>() >= 5)
                                {
                                    imgCut = nextFrame.Copy(rectangles[4]);
                                    //resizeScale = imageWindow5.Image.Size.Width / imgCut.Width;
                                    imageWindow5.Image = imgCut;//.Resize(resizeScale, INTER.CV_INTER_AREA);
                                    imageWindow5.Visible = true;
                                    if (rectangles.Count<Rectangle>() >= 6)
                                    {
                                        imgCut = nextFrame.Copy(rectangles[5]);
                                        //resizeScale = imageWindow6.Image.Size.Width / imgCut.Width;
                                        imageWindow6.Image = imgCut;//.Resize(resizeScale, INTER.CV_INTER_AREA);
                                        imageWindow6.Visible = true;
                                    }
                                }
                            }
                        }
                    }
                }
            }
            NumberOfFacesSmooth = NumberOfFacesSmooth * 0.75 + NumberOfFaces * .25;
            //long processingTime = new long();
            //nextFrame = FindPedestrian.Find(nextFrame, out processingTime);
            return nextFrame;
        }
        /// <summary>
        /// pass in a classifier and process the rect angle
        ///        CascadeClassifier face_cascade;
        ///     CascadeClassifier face2_cascade;
        ///     CascadeClassifier facep_cascade; 
        ///     CascadeClassifier bodyu_cascade;
        ///     CascadeClassifier bodyf_cascade;
        ///     CascadeClassifier bodyl_cascade; //haarcascade_lowerbody.xml
        /// </summary>
        Rectangle[] processDetectMultiScale(CascadeClassifier _cascadeClassifier, Image<Gray, byte> grayframe)
        {
            Debug.WriteLine("processDetectMultiScale" + _cascadeClassifier + " facecascade=" + (_cascadeClassifier == face_cascade));
            Rectangle[] rectangles = _cascadeClassifier.DetectMultiScale(grayframe, scaleFactor, minNeighbors, minSize, maxSize);
            return rectangles;
        }

        Image<Gray, byte> processFace(Image<Gray, byte> grayframe)
        {
                    // there's only one channel (greyscale), hence the zero index
                    //var faces = nextFrame.DetectHaarCascade(haar)[0];
                    //Image<Gray, byte> grayframe = nextFrame.Convert<Gray, byte>();
                    ////var faces =
                    //        grayframe.DetectHaarCascade(
                    //                face_cascade, 1.4, 4,
                    //                HAAR_DETECTION_TYPE.DO_CANNY_PRUNING,
                    //                new Size(nextFrame.Width / 8, nextFrame.Height / 8)
                    //                )[0];
            
            Rectangle[] rectangles = face_cascade.DetectMultiScale(grayframe, scaleFactor, 0, minSize, maxSize);
            foreach (var face in rectangles)
            {
                grayframe.Draw(face, new Gray(double.MaxValue), 3);
            }
            return grayframe;
        }

        private void btnPauseResume_Click(object sender, EventArgs e)
        {
            if (blnCaptureingInProcess == true)
            {
                Application.Idle -= processFrameAndUpdateGUI;
                btnPauseResume.Text = "resume";
                textBox1.AppendText("\n Paused Video stream");
                blnCaptureingInProcess = false;
            }
            else
            {
                Application.Idle += processFrameAndUpdateGUI;
                blnCaptureingInProcess = true;
                btnPauseResume.Text = "pause";
                textBox1.Text = "User Resumed Video stream";
            }
        }

        private void Form1_FormClosed(object sender, EventArgs e)
        {
            if (capWebcam != null)
                capWebcam.Dispose(); 
        }

        private void FaceCountButton_Click(object sender, EventArgs e)
        {
            Debug.WriteLine("  FaceCountButton_Click=" + e);
            
        }

        private void imageBox3_Click(object sender, EventArgs e)
        {
            Debug.WriteLine("imageBox3_Click");
            if (imageBoxOrig.Image != null)
            {
                //this.imageBoxProcesssed.Image = 
                    //processImage(new Image<Bgr, Byte>(imageBoxOrig.Image.Bitmap));
                resizeImage = maxWidth / (double)imgOriginal.Size.Width;
                imgOriginal = imgOriginal.Resize(resizeImage, Inter.Cubic);
                imageBoxOrig.Image = processImage(imgOriginal);
            }
            textBox1.Text = " " + this.listBoxClassifier.SelectedItem.ToString() +"\n \r counted="+this.NumberOfFaces +"\\r \\n  Avg=" + this.NumberOfFacesSmooth;
        }

        private void imageBoxOrig_Click(object sender, EventArgs e)
        {
            Debug.WriteLine("  imageBoxOrig_Click=" + e);
            //fc.convertColorImageSetGrey(this.imgOriginal);
            //fc.faceCounter();
            //textBox1.AppendText(" current image fc=" + fc.NumberOfFacesCounted + " smoothed=" + NumberOfFacesSmooth);

            resizeImage = maxWidth / (double)imgOriginal.Size.Width;
            imgOriginal = imgOriginal.Resize(resizeImage, Inter.Cubic);
            imageBoxOrig.Image = processImage(imgOriginal);
        }

        private void listBoxMinNeighbors_SelectedIndexChanged(object sender, EventArgs e)
        {
            Debug.WriteLine("  listBoxMinNeighbors_SelectedIndexChanged=" + e);
            minNeighbors = Convert.ToInt32(listBoxMinNeighbors.SelectedItem);
            fc.minNeighbors = this.minNeighbors;
            textBox1.AppendText(" \n minNeighbors" + minNeighbors);
        }

        private void listBoxScaleFactor_SelectedIndexChanged(object sender, EventArgs e)
        {
            Debug.WriteLine("  listBoxScaleFactor_SelectedIndexChanged=" + sender + e);
            scaleFactor = Convert.ToDouble(listBoxScaleFactor.SelectedItem);
            fc.scaleFactor = this.scaleFactor;
            textBox1.AppendText(" \n scaleFactor" + scaleFactor);
        }

        private void buttonSaveImg_Click(object sender, EventArgs e)
        {
            DateTime filestamp = DateTime.Now;
            string fileName = "currentImg" + filestamp.Year + filestamp.Month + filestamp.Day + filestamp.Hour + filestamp.Minute + filestamp.Second + ".bmp";
            Debug.WriteLine("  listBoxScaleFactor_SelectedIndexChanged=" + fileName + sender + e);
            imageBoxOrig.Image.Bitmap.Save(fileName);
        }

        private void populateListofImages()
        {
            Debug.WriteLine("populateListofImages");
            List<String> pictures = GetImagesPath("images");
            Debug.WriteLine("GetImagesPath # of picts" + pictures.Count);
            foreach (var pict in pictures)
            {
                listBoxPictureList.Items.Add(pict);
            }

        }

        private void populateListofVideos()
        {
            Debug.WriteLine("populateListofvideos");
            List<String> pictures = GetImagesPath("videos");
            Debug.WriteLine("videos # of picts" + pictures.Count);
            listBoxVideos.Items.Add("");
            foreach (var pict in pictures)
            {
                listBoxVideos.Items.Add(pict);
            }

        }
        public List<String> GetImagesPath(String folderName)
        {
            return Directory.GetFiles(folderName, "*.*", SearchOption.AllDirectories).ToList();
            //DirectoryInfo Folder;
            //FileInfo[] Images;

            //Folder = new DirectoryInfo(folderName);
            //Images = Folder.GetFiles();
            //List<String> imagesList = new List<String>();

            //for (int i = 0; i < Images.Length; i++)
            //{
            //    imagesList.Add(String.Format(@"{0}/{1}", folderName, Images[i].Name));
            //    // Console.WriteLine(String.Format(@"{0}/{1}", folderName, Images[i].Name));
            //}


            //return imagesList;
        }

        private void listBoxPictureList_SelectedIndexChanged(object sender, EventArgs e)
        {
            String imageFileName = listBoxPictureList.SelectedItem.ToString();
            Debug.WriteLine("listBoxPictureList_SelectedIndexChanged=" + imageFileName + sender + e);
            Image<Bgr, Byte> img1 = new Image<Bgr, Byte>(imageFileName);
            imageBoxOrig.Image = img1.Resize(imageBoxOrig.Width, imageBoxOrig.Height, Inter.Cubic, true);
            //Application.Idle -= processFrameAndUpdateGUI
            if (!blnCaptureingInProcess)
            {
                //this.imageBoxProcesssed.Image = 
                   // processImage(new Image<Bgr, Byte>(imageBoxOrig.Image.Bitmap));

                    resizeImage = maxWidth / (double)imgOriginal.Size.Width;
                    imgOriginal = imgOriginal.Resize(resizeImage, Inter.Cubic);
                    imageBoxOrig.Image = processImage(imgOriginal);
            }

        }

        private void listBoxClassifier_SelectedIndexChanged(object sender, EventArgs e)
        {
            CascadeClassifier runDMC = face_cascade; 
            String classifierClassName = listBoxClassifier.SelectedItem.ToString();
            Debug.WriteLine("classifierClassName_SelectedIndexChanged=" + classifierClassName +" "+ sender + e);
            //facea_cascade
            if (classifierClassName == "face2_cascade")
            {
                runDMC = face2_cascade;
            }
            else if (classifierClassName == "facep_cascade")
            {
                runDMC = facep_cascade;
            }
            else if (classifierClassName == "facea_cascade")
            {
                runDMC = facea_cascade;
            }
            else if (classifierClassName == "bodyl_cascade")
            {
                runDMC = bodyl_cascade;
            }
            else if (classifierClassName == "bodyu_cascade")
            {
                runDMC = bodyu_cascade;
            }
            else if (classifierClassName == "bodyf_cascade")
            {
                runDMC = bodyf_cascade;
            }
            active_cascade = runDMC;
            Debug.WriteLine(" new runDMC for active_cascade is = " + runDMC);
            if (!blnCaptureingInProcess)
            {
                //this.imageBoxProcesssed.Image = imageBoxOrig.Image
                    //processImage(new Image<Bgr, Byte>(imageBoxOrig.Image.Bitmap));

                    resizeImage = maxWidth / (double)imgOriginal.Size.Width;
                    imgOriginal = imgOriginal.Resize(resizeImage, Inter.Cubic);
                    imageBoxOrig.Image = processImage(imgOriginal);
            }
        }

        private void listBoxVideos_SelectedIndexChanged(object sender, EventArgs e)
        {
            String imageFileName = listBoxVideos.SelectedItem.ToString();
            Debug.WriteLine("listBoxVideos_SelectedIndexChanged=" + imageFileName + sender + e);
            try
            {
                if (imageFileName != null || imageFileName != "")

                    capWebcam = new Capture(imageFileName);
                else
                    capWebcam = new Capture(); // get standard video in if available, otherwise horrible error will occur. BUTTHEAD


                imgOriginal = capWebcam.QueryFrame().ToImage<Bgr, Byte>(); // gets first frame

            if (imgOriginal == null) return;
                this.imageBoxOrig.Image = imgOriginal;
                this.imageBoxOrig.Image = processImage(imgOriginal.Copy());
            }
            catch (Exception ohwow) { Debug.WriteLine("video crapped the bed..." + ohwow); }
        }
    }
}
